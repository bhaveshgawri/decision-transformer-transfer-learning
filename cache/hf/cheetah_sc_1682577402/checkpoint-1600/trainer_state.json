{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 100.0,
  "global_step": 1600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.31,
      "learning_rate": 1.5625e-06,
      "loss": 0.5962,
      "step": 5
    },
    {
      "epoch": 0.62,
      "learning_rate": 3.125e-06,
      "loss": 0.5933,
      "step": 10
    },
    {
      "epoch": 0.94,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.5904,
      "step": 15
    },
    {
      "epoch": 1.25,
      "learning_rate": 6.25e-06,
      "loss": 0.5814,
      "step": 20
    },
    {
      "epoch": 1.56,
      "learning_rate": 7.8125e-06,
      "loss": 0.584,
      "step": 25
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.5667,
      "step": 30
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.09375e-05,
      "loss": 0.5534,
      "step": 35
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.25e-05,
      "loss": 0.5408,
      "step": 40
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.4062500000000001e-05,
      "loss": 0.5378,
      "step": 45
    },
    {
      "epoch": 3.12,
      "learning_rate": 1.5625e-05,
      "loss": 0.5147,
      "step": 50
    },
    {
      "epoch": 3.44,
      "learning_rate": 1.71875e-05,
      "loss": 0.4995,
      "step": 55
    },
    {
      "epoch": 3.75,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.4759,
      "step": 60
    },
    {
      "epoch": 4.06,
      "learning_rate": 2.0312500000000002e-05,
      "loss": 0.4568,
      "step": 65
    },
    {
      "epoch": 4.38,
      "learning_rate": 2.1875e-05,
      "loss": 0.4338,
      "step": 70
    },
    {
      "epoch": 4.69,
      "learning_rate": 2.34375e-05,
      "loss": 0.4115,
      "step": 75
    },
    {
      "epoch": 5.0,
      "learning_rate": 2.5e-05,
      "loss": 0.3904,
      "step": 80
    },
    {
      "epoch": 5.31,
      "learning_rate": 2.6562500000000002e-05,
      "loss": 0.3614,
      "step": 85
    },
    {
      "epoch": 5.62,
      "learning_rate": 2.8125000000000003e-05,
      "loss": 0.3393,
      "step": 90
    },
    {
      "epoch": 5.94,
      "learning_rate": 2.96875e-05,
      "loss": 0.3116,
      "step": 95
    },
    {
      "epoch": 6.25,
      "learning_rate": 3.125e-05,
      "loss": 0.2865,
      "step": 100
    },
    {
      "epoch": 6.56,
      "learning_rate": 3.2812500000000005e-05,
      "loss": 0.2674,
      "step": 105
    },
    {
      "epoch": 6.88,
      "learning_rate": 3.4375e-05,
      "loss": 0.2428,
      "step": 110
    },
    {
      "epoch": 7.19,
      "learning_rate": 3.59375e-05,
      "loss": 0.221,
      "step": 115
    },
    {
      "epoch": 7.5,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.21,
      "step": 120
    },
    {
      "epoch": 7.81,
      "learning_rate": 3.90625e-05,
      "loss": 0.1846,
      "step": 125
    },
    {
      "epoch": 8.12,
      "learning_rate": 4.0625000000000005e-05,
      "loss": 0.1667,
      "step": 130
    },
    {
      "epoch": 8.44,
      "learning_rate": 4.21875e-05,
      "loss": 0.1664,
      "step": 135
    },
    {
      "epoch": 8.75,
      "learning_rate": 4.375e-05,
      "loss": 0.1479,
      "step": 140
    },
    {
      "epoch": 9.06,
      "learning_rate": 4.5312500000000004e-05,
      "loss": 0.1439,
      "step": 145
    },
    {
      "epoch": 9.38,
      "learning_rate": 4.6875e-05,
      "loss": 0.1399,
      "step": 150
    },
    {
      "epoch": 9.69,
      "learning_rate": 4.8437500000000005e-05,
      "loss": 0.127,
      "step": 155
    },
    {
      "epoch": 10.0,
      "learning_rate": 5e-05,
      "loss": 0.1182,
      "step": 160
    },
    {
      "epoch": 10.31,
      "learning_rate": 5.15625e-05,
      "loss": 0.1149,
      "step": 165
    },
    {
      "epoch": 10.62,
      "learning_rate": 5.3125000000000004e-05,
      "loss": 0.1102,
      "step": 170
    },
    {
      "epoch": 10.94,
      "learning_rate": 5.46875e-05,
      "loss": 0.1114,
      "step": 175
    },
    {
      "epoch": 11.25,
      "learning_rate": 5.6250000000000005e-05,
      "loss": 0.104,
      "step": 180
    },
    {
      "epoch": 11.56,
      "learning_rate": 5.78125e-05,
      "loss": 0.1021,
      "step": 185
    },
    {
      "epoch": 11.88,
      "learning_rate": 5.9375e-05,
      "loss": 0.1007,
      "step": 190
    },
    {
      "epoch": 12.19,
      "learning_rate": 6.0937500000000004e-05,
      "loss": 0.1046,
      "step": 195
    },
    {
      "epoch": 12.5,
      "learning_rate": 6.25e-05,
      "loss": 0.1001,
      "step": 200
    },
    {
      "epoch": 12.81,
      "learning_rate": 6.40625e-05,
      "loss": 0.0943,
      "step": 205
    },
    {
      "epoch": 13.12,
      "learning_rate": 6.562500000000001e-05,
      "loss": 0.0917,
      "step": 210
    },
    {
      "epoch": 13.44,
      "learning_rate": 6.71875e-05,
      "loss": 0.0858,
      "step": 215
    },
    {
      "epoch": 13.75,
      "learning_rate": 6.875e-05,
      "loss": 0.0893,
      "step": 220
    },
    {
      "epoch": 14.06,
      "learning_rate": 7.031250000000001e-05,
      "loss": 0.0897,
      "step": 225
    },
    {
      "epoch": 14.38,
      "learning_rate": 7.1875e-05,
      "loss": 0.0835,
      "step": 230
    },
    {
      "epoch": 14.69,
      "learning_rate": 7.34375e-05,
      "loss": 0.0846,
      "step": 235
    },
    {
      "epoch": 15.0,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0758,
      "step": 240
    },
    {
      "epoch": 15.31,
      "learning_rate": 7.65625e-05,
      "loss": 0.0815,
      "step": 245
    },
    {
      "epoch": 15.62,
      "learning_rate": 7.8125e-05,
      "loss": 0.0851,
      "step": 250
    },
    {
      "epoch": 15.94,
      "learning_rate": 7.96875e-05,
      "loss": 0.0822,
      "step": 255
    },
    {
      "epoch": 16.25,
      "learning_rate": 8.125000000000001e-05,
      "loss": 0.0771,
      "step": 260
    },
    {
      "epoch": 16.56,
      "learning_rate": 8.28125e-05,
      "loss": 0.0807,
      "step": 265
    },
    {
      "epoch": 16.88,
      "learning_rate": 8.4375e-05,
      "loss": 0.0759,
      "step": 270
    },
    {
      "epoch": 17.19,
      "learning_rate": 8.593750000000001e-05,
      "loss": 0.075,
      "step": 275
    },
    {
      "epoch": 17.5,
      "learning_rate": 8.75e-05,
      "loss": 0.0767,
      "step": 280
    },
    {
      "epoch": 17.81,
      "learning_rate": 8.90625e-05,
      "loss": 0.0724,
      "step": 285
    },
    {
      "epoch": 18.12,
      "learning_rate": 9.062500000000001e-05,
      "loss": 0.0695,
      "step": 290
    },
    {
      "epoch": 18.44,
      "learning_rate": 9.21875e-05,
      "loss": 0.0731,
      "step": 295
    },
    {
      "epoch": 18.75,
      "learning_rate": 9.375e-05,
      "loss": 0.0695,
      "step": 300
    },
    {
      "epoch": 19.06,
      "learning_rate": 9.53125e-05,
      "loss": 0.0694,
      "step": 305
    },
    {
      "epoch": 19.38,
      "learning_rate": 9.687500000000001e-05,
      "loss": 0.0719,
      "step": 310
    },
    {
      "epoch": 19.69,
      "learning_rate": 9.84375e-05,
      "loss": 0.0715,
      "step": 315
    },
    {
      "epoch": 20.0,
      "learning_rate": 0.0001,
      "loss": 0.0736,
      "step": 320
    },
    {
      "epoch": 20.31,
      "learning_rate": 9.960937500000001e-05,
      "loss": 0.0684,
      "step": 325
    },
    {
      "epoch": 20.62,
      "learning_rate": 9.921875000000001e-05,
      "loss": 0.067,
      "step": 330
    },
    {
      "epoch": 20.94,
      "learning_rate": 9.8828125e-05,
      "loss": 0.0677,
      "step": 335
    },
    {
      "epoch": 21.25,
      "learning_rate": 9.84375e-05,
      "loss": 0.0674,
      "step": 340
    },
    {
      "epoch": 21.56,
      "learning_rate": 9.8046875e-05,
      "loss": 0.063,
      "step": 345
    },
    {
      "epoch": 21.88,
      "learning_rate": 9.765625e-05,
      "loss": 0.0635,
      "step": 350
    },
    {
      "epoch": 22.19,
      "learning_rate": 9.726562500000001e-05,
      "loss": 0.0644,
      "step": 355
    },
    {
      "epoch": 22.5,
      "learning_rate": 9.687500000000001e-05,
      "loss": 0.0638,
      "step": 360
    },
    {
      "epoch": 22.81,
      "learning_rate": 9.6484375e-05,
      "loss": 0.0598,
      "step": 365
    },
    {
      "epoch": 23.12,
      "learning_rate": 9.609375e-05,
      "loss": 0.0627,
      "step": 370
    },
    {
      "epoch": 23.44,
      "learning_rate": 9.5703125e-05,
      "loss": 0.0608,
      "step": 375
    },
    {
      "epoch": 23.75,
      "learning_rate": 9.53125e-05,
      "loss": 0.0608,
      "step": 380
    },
    {
      "epoch": 24.06,
      "learning_rate": 9.492187500000001e-05,
      "loss": 0.067,
      "step": 385
    },
    {
      "epoch": 24.38,
      "learning_rate": 9.453125000000001e-05,
      "loss": 0.0605,
      "step": 390
    },
    {
      "epoch": 24.69,
      "learning_rate": 9.4140625e-05,
      "loss": 0.063,
      "step": 395
    },
    {
      "epoch": 25.0,
      "learning_rate": 9.375e-05,
      "loss": 0.063,
      "step": 400
    },
    {
      "epoch": 25.31,
      "learning_rate": 9.3359375e-05,
      "loss": 0.0601,
      "step": 405
    },
    {
      "epoch": 25.62,
      "learning_rate": 9.296875e-05,
      "loss": 0.0599,
      "step": 410
    },
    {
      "epoch": 25.94,
      "learning_rate": 9.257812500000001e-05,
      "loss": 0.0568,
      "step": 415
    },
    {
      "epoch": 26.25,
      "learning_rate": 9.21875e-05,
      "loss": 0.057,
      "step": 420
    },
    {
      "epoch": 26.56,
      "learning_rate": 9.1796875e-05,
      "loss": 0.0626,
      "step": 425
    },
    {
      "epoch": 26.88,
      "learning_rate": 9.140625e-05,
      "loss": 0.0569,
      "step": 430
    },
    {
      "epoch": 27.19,
      "learning_rate": 9.1015625e-05,
      "loss": 0.0589,
      "step": 435
    },
    {
      "epoch": 27.5,
      "learning_rate": 9.062500000000001e-05,
      "loss": 0.0538,
      "step": 440
    },
    {
      "epoch": 27.81,
      "learning_rate": 9.023437500000001e-05,
      "loss": 0.0551,
      "step": 445
    },
    {
      "epoch": 28.12,
      "learning_rate": 8.984375e-05,
      "loss": 0.0557,
      "step": 450
    },
    {
      "epoch": 28.44,
      "learning_rate": 8.9453125e-05,
      "loss": 0.0583,
      "step": 455
    },
    {
      "epoch": 28.75,
      "learning_rate": 8.90625e-05,
      "loss": 0.0588,
      "step": 460
    },
    {
      "epoch": 29.06,
      "learning_rate": 8.8671875e-05,
      "loss": 0.0561,
      "step": 465
    },
    {
      "epoch": 29.38,
      "learning_rate": 8.828125000000001e-05,
      "loss": 0.0562,
      "step": 470
    },
    {
      "epoch": 29.69,
      "learning_rate": 8.789062500000001e-05,
      "loss": 0.0554,
      "step": 475
    },
    {
      "epoch": 30.0,
      "learning_rate": 8.75e-05,
      "loss": 0.0554,
      "step": 480
    },
    {
      "epoch": 30.31,
      "learning_rate": 8.7109375e-05,
      "loss": 0.0552,
      "step": 485
    },
    {
      "epoch": 30.62,
      "learning_rate": 8.671875e-05,
      "loss": 0.0525,
      "step": 490
    },
    {
      "epoch": 30.94,
      "learning_rate": 8.6328125e-05,
      "loss": 0.0534,
      "step": 495
    },
    {
      "epoch": 31.25,
      "learning_rate": 8.593750000000001e-05,
      "loss": 0.0565,
      "step": 500
    },
    {
      "epoch": 31.56,
      "learning_rate": 8.5546875e-05,
      "loss": 0.054,
      "step": 505
    },
    {
      "epoch": 31.88,
      "learning_rate": 8.515625e-05,
      "loss": 0.0547,
      "step": 510
    },
    {
      "epoch": 32.19,
      "learning_rate": 8.4765625e-05,
      "loss": 0.0573,
      "step": 515
    },
    {
      "epoch": 32.5,
      "learning_rate": 8.4375e-05,
      "loss": 0.0538,
      "step": 520
    },
    {
      "epoch": 32.81,
      "learning_rate": 8.398437500000001e-05,
      "loss": 0.0512,
      "step": 525
    },
    {
      "epoch": 33.12,
      "learning_rate": 8.359375000000001e-05,
      "loss": 0.0536,
      "step": 530
    },
    {
      "epoch": 33.44,
      "learning_rate": 8.3203125e-05,
      "loss": 0.0556,
      "step": 535
    },
    {
      "epoch": 33.75,
      "learning_rate": 8.28125e-05,
      "loss": 0.0523,
      "step": 540
    },
    {
      "epoch": 34.06,
      "learning_rate": 8.2421875e-05,
      "loss": 0.0526,
      "step": 545
    },
    {
      "epoch": 34.38,
      "learning_rate": 8.203125e-05,
      "loss": 0.0525,
      "step": 550
    },
    {
      "epoch": 34.69,
      "learning_rate": 8.164062500000001e-05,
      "loss": 0.0564,
      "step": 555
    },
    {
      "epoch": 35.0,
      "learning_rate": 8.125000000000001e-05,
      "loss": 0.0531,
      "step": 560
    },
    {
      "epoch": 35.31,
      "learning_rate": 8.0859375e-05,
      "loss": 0.0468,
      "step": 565
    },
    {
      "epoch": 35.62,
      "learning_rate": 8.046875e-05,
      "loss": 0.0589,
      "step": 570
    },
    {
      "epoch": 35.94,
      "learning_rate": 8.0078125e-05,
      "loss": 0.055,
      "step": 575
    },
    {
      "epoch": 36.25,
      "learning_rate": 7.96875e-05,
      "loss": 0.0489,
      "step": 580
    },
    {
      "epoch": 36.56,
      "learning_rate": 7.929687500000001e-05,
      "loss": 0.0543,
      "step": 585
    },
    {
      "epoch": 36.88,
      "learning_rate": 7.890625000000001e-05,
      "loss": 0.0555,
      "step": 590
    },
    {
      "epoch": 37.19,
      "learning_rate": 7.8515625e-05,
      "loss": 0.0508,
      "step": 595
    },
    {
      "epoch": 37.5,
      "learning_rate": 7.8125e-05,
      "loss": 0.0496,
      "step": 600
    },
    {
      "epoch": 37.81,
      "learning_rate": 7.7734375e-05,
      "loss": 0.0552,
      "step": 605
    },
    {
      "epoch": 38.12,
      "learning_rate": 7.734375e-05,
      "loss": 0.0515,
      "step": 610
    },
    {
      "epoch": 38.44,
      "learning_rate": 7.695312500000001e-05,
      "loss": 0.0489,
      "step": 615
    },
    {
      "epoch": 38.75,
      "learning_rate": 7.65625e-05,
      "loss": 0.055,
      "step": 620
    },
    {
      "epoch": 39.06,
      "learning_rate": 7.6171875e-05,
      "loss": 0.0493,
      "step": 625
    },
    {
      "epoch": 39.38,
      "learning_rate": 7.578125e-05,
      "loss": 0.0489,
      "step": 630
    },
    {
      "epoch": 39.69,
      "learning_rate": 7.5390625e-05,
      "loss": 0.0496,
      "step": 635
    },
    {
      "epoch": 40.0,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0538,
      "step": 640
    },
    {
      "epoch": 40.31,
      "learning_rate": 7.460937500000001e-05,
      "loss": 0.0505,
      "step": 645
    },
    {
      "epoch": 40.62,
      "learning_rate": 7.421875e-05,
      "loss": 0.0526,
      "step": 650
    },
    {
      "epoch": 40.94,
      "learning_rate": 7.3828125e-05,
      "loss": 0.0493,
      "step": 655
    },
    {
      "epoch": 41.25,
      "learning_rate": 7.34375e-05,
      "loss": 0.0502,
      "step": 660
    },
    {
      "epoch": 41.56,
      "learning_rate": 7.3046875e-05,
      "loss": 0.0467,
      "step": 665
    },
    {
      "epoch": 41.88,
      "learning_rate": 7.265625000000001e-05,
      "loss": 0.0477,
      "step": 670
    },
    {
      "epoch": 42.19,
      "learning_rate": 7.226562500000001e-05,
      "loss": 0.0522,
      "step": 675
    },
    {
      "epoch": 42.5,
      "learning_rate": 7.1875e-05,
      "loss": 0.052,
      "step": 680
    },
    {
      "epoch": 42.81,
      "learning_rate": 7.1484375e-05,
      "loss": 0.0501,
      "step": 685
    },
    {
      "epoch": 43.12,
      "learning_rate": 7.109375e-05,
      "loss": 0.0488,
      "step": 690
    },
    {
      "epoch": 43.44,
      "learning_rate": 7.0703125e-05,
      "loss": 0.0545,
      "step": 695
    },
    {
      "epoch": 43.75,
      "learning_rate": 7.031250000000001e-05,
      "loss": 0.0479,
      "step": 700
    },
    {
      "epoch": 44.06,
      "learning_rate": 6.9921875e-05,
      "loss": 0.0509,
      "step": 705
    },
    {
      "epoch": 44.38,
      "learning_rate": 6.953125e-05,
      "loss": 0.0445,
      "step": 710
    },
    {
      "epoch": 44.69,
      "learning_rate": 6.9140625e-05,
      "loss": 0.0453,
      "step": 715
    },
    {
      "epoch": 45.0,
      "learning_rate": 6.875e-05,
      "loss": 0.0478,
      "step": 720
    },
    {
      "epoch": 45.31,
      "learning_rate": 6.8359375e-05,
      "loss": 0.0506,
      "step": 725
    },
    {
      "epoch": 45.62,
      "learning_rate": 6.796875000000001e-05,
      "loss": 0.0494,
      "step": 730
    },
    {
      "epoch": 45.94,
      "learning_rate": 6.7578125e-05,
      "loss": 0.0507,
      "step": 735
    },
    {
      "epoch": 46.25,
      "learning_rate": 6.71875e-05,
      "loss": 0.0492,
      "step": 740
    },
    {
      "epoch": 46.56,
      "learning_rate": 6.6796875e-05,
      "loss": 0.0491,
      "step": 745
    },
    {
      "epoch": 46.88,
      "learning_rate": 6.640625e-05,
      "loss": 0.045,
      "step": 750
    },
    {
      "epoch": 47.19,
      "learning_rate": 6.601562500000001e-05,
      "loss": 0.0466,
      "step": 755
    },
    {
      "epoch": 47.5,
      "learning_rate": 6.562500000000001e-05,
      "loss": 0.049,
      "step": 760
    },
    {
      "epoch": 47.81,
      "learning_rate": 6.5234375e-05,
      "loss": 0.0499,
      "step": 765
    },
    {
      "epoch": 48.12,
      "learning_rate": 6.484375e-05,
      "loss": 0.0482,
      "step": 770
    },
    {
      "epoch": 48.44,
      "learning_rate": 6.4453125e-05,
      "loss": 0.0472,
      "step": 775
    },
    {
      "epoch": 48.75,
      "learning_rate": 6.40625e-05,
      "loss": 0.0486,
      "step": 780
    },
    {
      "epoch": 49.06,
      "learning_rate": 6.367187500000001e-05,
      "loss": 0.0474,
      "step": 785
    },
    {
      "epoch": 49.38,
      "learning_rate": 6.328125e-05,
      "loss": 0.0501,
      "step": 790
    },
    {
      "epoch": 49.69,
      "learning_rate": 6.2890625e-05,
      "loss": 0.0505,
      "step": 795
    },
    {
      "epoch": 50.0,
      "learning_rate": 6.25e-05,
      "loss": 0.0473,
      "step": 800
    },
    {
      "epoch": 50.31,
      "learning_rate": 6.2109375e-05,
      "loss": 0.046,
      "step": 805
    },
    {
      "epoch": 50.62,
      "learning_rate": 6.171875e-05,
      "loss": 0.0485,
      "step": 810
    },
    {
      "epoch": 50.94,
      "learning_rate": 6.132812500000001e-05,
      "loss": 0.0495,
      "step": 815
    },
    {
      "epoch": 51.25,
      "learning_rate": 6.0937500000000004e-05,
      "loss": 0.046,
      "step": 820
    },
    {
      "epoch": 51.56,
      "learning_rate": 6.0546875e-05,
      "loss": 0.0502,
      "step": 825
    },
    {
      "epoch": 51.88,
      "learning_rate": 6.015625e-05,
      "loss": 0.0457,
      "step": 830
    },
    {
      "epoch": 52.19,
      "learning_rate": 5.9765625000000004e-05,
      "loss": 0.0504,
      "step": 835
    },
    {
      "epoch": 52.5,
      "learning_rate": 5.9375e-05,
      "loss": 0.0474,
      "step": 840
    },
    {
      "epoch": 52.81,
      "learning_rate": 5.8984375e-05,
      "loss": 0.0468,
      "step": 845
    },
    {
      "epoch": 53.12,
      "learning_rate": 5.8593750000000005e-05,
      "loss": 0.0472,
      "step": 850
    },
    {
      "epoch": 53.44,
      "learning_rate": 5.8203125e-05,
      "loss": 0.047,
      "step": 855
    },
    {
      "epoch": 53.75,
      "learning_rate": 5.78125e-05,
      "loss": 0.0474,
      "step": 860
    },
    {
      "epoch": 54.06,
      "learning_rate": 5.7421875000000005e-05,
      "loss": 0.0457,
      "step": 865
    },
    {
      "epoch": 54.38,
      "learning_rate": 5.703125e-05,
      "loss": 0.0468,
      "step": 870
    },
    {
      "epoch": 54.69,
      "learning_rate": 5.6640625e-05,
      "loss": 0.0476,
      "step": 875
    },
    {
      "epoch": 55.0,
      "learning_rate": 5.6250000000000005e-05,
      "loss": 0.0473,
      "step": 880
    },
    {
      "epoch": 55.31,
      "learning_rate": 5.5859375e-05,
      "loss": 0.0493,
      "step": 885
    },
    {
      "epoch": 55.62,
      "learning_rate": 5.546875e-05,
      "loss": 0.0482,
      "step": 890
    },
    {
      "epoch": 55.94,
      "learning_rate": 5.5078125000000006e-05,
      "loss": 0.0484,
      "step": 895
    },
    {
      "epoch": 56.25,
      "learning_rate": 5.46875e-05,
      "loss": 0.0492,
      "step": 900
    },
    {
      "epoch": 56.56,
      "learning_rate": 5.4296875000000004e-05,
      "loss": 0.0459,
      "step": 905
    },
    {
      "epoch": 56.88,
      "learning_rate": 5.3906250000000006e-05,
      "loss": 0.0476,
      "step": 910
    },
    {
      "epoch": 57.19,
      "learning_rate": 5.3515625e-05,
      "loss": 0.0503,
      "step": 915
    },
    {
      "epoch": 57.5,
      "learning_rate": 5.3125000000000004e-05,
      "loss": 0.0505,
      "step": 920
    },
    {
      "epoch": 57.81,
      "learning_rate": 5.2734375e-05,
      "loss": 0.0458,
      "step": 925
    },
    {
      "epoch": 58.12,
      "learning_rate": 5.234375e-05,
      "loss": 0.0498,
      "step": 930
    },
    {
      "epoch": 58.44,
      "learning_rate": 5.1953125000000004e-05,
      "loss": 0.046,
      "step": 935
    },
    {
      "epoch": 58.75,
      "learning_rate": 5.15625e-05,
      "loss": 0.0474,
      "step": 940
    },
    {
      "epoch": 59.06,
      "learning_rate": 5.1171875e-05,
      "loss": 0.0508,
      "step": 945
    },
    {
      "epoch": 59.38,
      "learning_rate": 5.0781250000000004e-05,
      "loss": 0.0475,
      "step": 950
    },
    {
      "epoch": 59.69,
      "learning_rate": 5.0390625e-05,
      "loss": 0.0479,
      "step": 955
    },
    {
      "epoch": 60.0,
      "learning_rate": 5e-05,
      "loss": 0.0468,
      "step": 960
    },
    {
      "epoch": 60.31,
      "learning_rate": 4.9609375000000005e-05,
      "loss": 0.0461,
      "step": 965
    },
    {
      "epoch": 60.62,
      "learning_rate": 4.921875e-05,
      "loss": 0.0485,
      "step": 970
    },
    {
      "epoch": 60.94,
      "learning_rate": 4.8828125e-05,
      "loss": 0.0472,
      "step": 975
    },
    {
      "epoch": 61.25,
      "learning_rate": 4.8437500000000005e-05,
      "loss": 0.0452,
      "step": 980
    },
    {
      "epoch": 61.56,
      "learning_rate": 4.8046875e-05,
      "loss": 0.0451,
      "step": 985
    },
    {
      "epoch": 61.88,
      "learning_rate": 4.765625e-05,
      "loss": 0.0425,
      "step": 990
    },
    {
      "epoch": 62.19,
      "learning_rate": 4.7265625000000005e-05,
      "loss": 0.0462,
      "step": 995
    },
    {
      "epoch": 62.5,
      "learning_rate": 4.6875e-05,
      "loss": 0.0459,
      "step": 1000
    },
    {
      "epoch": 62.81,
      "learning_rate": 4.6484375e-05,
      "loss": 0.0484,
      "step": 1005
    },
    {
      "epoch": 63.12,
      "learning_rate": 4.609375e-05,
      "loss": 0.0478,
      "step": 1010
    },
    {
      "epoch": 63.44,
      "learning_rate": 4.5703125e-05,
      "loss": 0.0465,
      "step": 1015
    },
    {
      "epoch": 63.75,
      "learning_rate": 4.5312500000000004e-05,
      "loss": 0.0443,
      "step": 1020
    },
    {
      "epoch": 64.06,
      "learning_rate": 4.4921875e-05,
      "loss": 0.0466,
      "step": 1025
    },
    {
      "epoch": 64.38,
      "learning_rate": 4.453125e-05,
      "loss": 0.0434,
      "step": 1030
    },
    {
      "epoch": 64.69,
      "learning_rate": 4.4140625000000004e-05,
      "loss": 0.0436,
      "step": 1035
    },
    {
      "epoch": 65.0,
      "learning_rate": 4.375e-05,
      "loss": 0.0457,
      "step": 1040
    },
    {
      "epoch": 65.31,
      "learning_rate": 4.3359375e-05,
      "loss": 0.0436,
      "step": 1045
    },
    {
      "epoch": 65.62,
      "learning_rate": 4.2968750000000004e-05,
      "loss": 0.0494,
      "step": 1050
    },
    {
      "epoch": 65.94,
      "learning_rate": 4.2578125e-05,
      "loss": 0.045,
      "step": 1055
    },
    {
      "epoch": 66.25,
      "learning_rate": 4.21875e-05,
      "loss": 0.0432,
      "step": 1060
    },
    {
      "epoch": 66.56,
      "learning_rate": 4.1796875000000005e-05,
      "loss": 0.0462,
      "step": 1065
    },
    {
      "epoch": 66.88,
      "learning_rate": 4.140625e-05,
      "loss": 0.0445,
      "step": 1070
    },
    {
      "epoch": 67.19,
      "learning_rate": 4.1015625e-05,
      "loss": 0.0458,
      "step": 1075
    },
    {
      "epoch": 67.5,
      "learning_rate": 4.0625000000000005e-05,
      "loss": 0.0455,
      "step": 1080
    },
    {
      "epoch": 67.81,
      "learning_rate": 4.0234375e-05,
      "loss": 0.046,
      "step": 1085
    },
    {
      "epoch": 68.12,
      "learning_rate": 3.984375e-05,
      "loss": 0.0451,
      "step": 1090
    },
    {
      "epoch": 68.44,
      "learning_rate": 3.9453125000000005e-05,
      "loss": 0.0467,
      "step": 1095
    },
    {
      "epoch": 68.75,
      "learning_rate": 3.90625e-05,
      "loss": 0.0474,
      "step": 1100
    },
    {
      "epoch": 69.06,
      "learning_rate": 3.8671875e-05,
      "loss": 0.0435,
      "step": 1105
    },
    {
      "epoch": 69.38,
      "learning_rate": 3.828125e-05,
      "loss": 0.0462,
      "step": 1110
    },
    {
      "epoch": 69.69,
      "learning_rate": 3.7890625e-05,
      "loss": 0.0476,
      "step": 1115
    },
    {
      "epoch": 70.0,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0457,
      "step": 1120
    },
    {
      "epoch": 70.31,
      "learning_rate": 3.7109375e-05,
      "loss": 0.0467,
      "step": 1125
    },
    {
      "epoch": 70.62,
      "learning_rate": 3.671875e-05,
      "loss": 0.0453,
      "step": 1130
    },
    {
      "epoch": 70.94,
      "learning_rate": 3.6328125000000004e-05,
      "loss": 0.046,
      "step": 1135
    },
    {
      "epoch": 71.25,
      "learning_rate": 3.59375e-05,
      "loss": 0.0474,
      "step": 1140
    },
    {
      "epoch": 71.56,
      "learning_rate": 3.5546875e-05,
      "loss": 0.0457,
      "step": 1145
    },
    {
      "epoch": 71.88,
      "learning_rate": 3.5156250000000004e-05,
      "loss": 0.0464,
      "step": 1150
    },
    {
      "epoch": 72.19,
      "learning_rate": 3.4765625e-05,
      "loss": 0.0482,
      "step": 1155
    },
    {
      "epoch": 72.5,
      "learning_rate": 3.4375e-05,
      "loss": 0.0442,
      "step": 1160
    },
    {
      "epoch": 72.81,
      "learning_rate": 3.3984375000000004e-05,
      "loss": 0.0428,
      "step": 1165
    },
    {
      "epoch": 73.12,
      "learning_rate": 3.359375e-05,
      "loss": 0.0447,
      "step": 1170
    },
    {
      "epoch": 73.44,
      "learning_rate": 3.3203125e-05,
      "loss": 0.0448,
      "step": 1175
    },
    {
      "epoch": 73.75,
      "learning_rate": 3.2812500000000005e-05,
      "loss": 0.0448,
      "step": 1180
    },
    {
      "epoch": 74.06,
      "learning_rate": 3.2421875e-05,
      "loss": 0.0432,
      "step": 1185
    },
    {
      "epoch": 74.38,
      "learning_rate": 3.203125e-05,
      "loss": 0.0425,
      "step": 1190
    },
    {
      "epoch": 74.69,
      "learning_rate": 3.1640625e-05,
      "loss": 0.0442,
      "step": 1195
    },
    {
      "epoch": 75.0,
      "learning_rate": 3.125e-05,
      "loss": 0.0441,
      "step": 1200
    },
    {
      "epoch": 75.31,
      "learning_rate": 3.0859375e-05,
      "loss": 0.0437,
      "step": 1205
    },
    {
      "epoch": 75.62,
      "learning_rate": 3.0468750000000002e-05,
      "loss": 0.0432,
      "step": 1210
    },
    {
      "epoch": 75.94,
      "learning_rate": 3.0078125e-05,
      "loss": 0.0464,
      "step": 1215
    },
    {
      "epoch": 76.25,
      "learning_rate": 2.96875e-05,
      "loss": 0.047,
      "step": 1220
    },
    {
      "epoch": 76.56,
      "learning_rate": 2.9296875000000002e-05,
      "loss": 0.0448,
      "step": 1225
    },
    {
      "epoch": 76.88,
      "learning_rate": 2.890625e-05,
      "loss": 0.0456,
      "step": 1230
    },
    {
      "epoch": 77.19,
      "learning_rate": 2.8515625e-05,
      "loss": 0.0471,
      "step": 1235
    },
    {
      "epoch": 77.5,
      "learning_rate": 2.8125000000000003e-05,
      "loss": 0.0439,
      "step": 1240
    },
    {
      "epoch": 77.81,
      "learning_rate": 2.7734375e-05,
      "loss": 0.044,
      "step": 1245
    },
    {
      "epoch": 78.12,
      "learning_rate": 2.734375e-05,
      "loss": 0.0457,
      "step": 1250
    },
    {
      "epoch": 78.44,
      "learning_rate": 2.6953125000000003e-05,
      "loss": 0.0476,
      "step": 1255
    },
    {
      "epoch": 78.75,
      "learning_rate": 2.6562500000000002e-05,
      "loss": 0.0495,
      "step": 1260
    },
    {
      "epoch": 79.06,
      "learning_rate": 2.6171875e-05,
      "loss": 0.0445,
      "step": 1265
    },
    {
      "epoch": 79.38,
      "learning_rate": 2.578125e-05,
      "loss": 0.0467,
      "step": 1270
    },
    {
      "epoch": 79.69,
      "learning_rate": 2.5390625000000002e-05,
      "loss": 0.0416,
      "step": 1275
    },
    {
      "epoch": 80.0,
      "learning_rate": 2.5e-05,
      "loss": 0.0454,
      "step": 1280
    },
    {
      "epoch": 80.31,
      "learning_rate": 2.4609375e-05,
      "loss": 0.0431,
      "step": 1285
    },
    {
      "epoch": 80.62,
      "learning_rate": 2.4218750000000003e-05,
      "loss": 0.0432,
      "step": 1290
    },
    {
      "epoch": 80.94,
      "learning_rate": 2.3828125e-05,
      "loss": 0.0417,
      "step": 1295
    },
    {
      "epoch": 81.25,
      "learning_rate": 2.34375e-05,
      "loss": 0.0427,
      "step": 1300
    },
    {
      "epoch": 81.56,
      "learning_rate": 2.3046875e-05,
      "loss": 0.0464,
      "step": 1305
    },
    {
      "epoch": 81.88,
      "learning_rate": 2.2656250000000002e-05,
      "loss": 0.0432,
      "step": 1310
    },
    {
      "epoch": 82.19,
      "learning_rate": 2.2265625e-05,
      "loss": 0.043,
      "step": 1315
    },
    {
      "epoch": 82.5,
      "learning_rate": 2.1875e-05,
      "loss": 0.0453,
      "step": 1320
    },
    {
      "epoch": 82.81,
      "learning_rate": 2.1484375000000002e-05,
      "loss": 0.0433,
      "step": 1325
    },
    {
      "epoch": 83.12,
      "learning_rate": 2.109375e-05,
      "loss": 0.0444,
      "step": 1330
    },
    {
      "epoch": 83.44,
      "learning_rate": 2.0703125e-05,
      "loss": 0.0421,
      "step": 1335
    },
    {
      "epoch": 83.75,
      "learning_rate": 2.0312500000000002e-05,
      "loss": 0.0415,
      "step": 1340
    },
    {
      "epoch": 84.06,
      "learning_rate": 1.9921875e-05,
      "loss": 0.0431,
      "step": 1345
    },
    {
      "epoch": 84.38,
      "learning_rate": 1.953125e-05,
      "loss": 0.0449,
      "step": 1350
    },
    {
      "epoch": 84.69,
      "learning_rate": 1.9140625e-05,
      "loss": 0.0446,
      "step": 1355
    },
    {
      "epoch": 85.0,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.044,
      "step": 1360
    },
    {
      "epoch": 85.31,
      "learning_rate": 1.8359375e-05,
      "loss": 0.045,
      "step": 1365
    },
    {
      "epoch": 85.62,
      "learning_rate": 1.796875e-05,
      "loss": 0.042,
      "step": 1370
    },
    {
      "epoch": 85.94,
      "learning_rate": 1.7578125000000002e-05,
      "loss": 0.0448,
      "step": 1375
    },
    {
      "epoch": 86.25,
      "learning_rate": 1.71875e-05,
      "loss": 0.0423,
      "step": 1380
    },
    {
      "epoch": 86.56,
      "learning_rate": 1.6796875e-05,
      "loss": 0.045,
      "step": 1385
    },
    {
      "epoch": 86.88,
      "learning_rate": 1.6406250000000002e-05,
      "loss": 0.0457,
      "step": 1390
    },
    {
      "epoch": 87.19,
      "learning_rate": 1.6015625e-05,
      "loss": 0.0424,
      "step": 1395
    },
    {
      "epoch": 87.5,
      "learning_rate": 1.5625e-05,
      "loss": 0.0434,
      "step": 1400
    },
    {
      "epoch": 87.81,
      "learning_rate": 1.5234375000000001e-05,
      "loss": 0.0445,
      "step": 1405
    },
    {
      "epoch": 88.12,
      "learning_rate": 1.484375e-05,
      "loss": 0.0432,
      "step": 1410
    },
    {
      "epoch": 88.44,
      "learning_rate": 1.4453125e-05,
      "loss": 0.0429,
      "step": 1415
    },
    {
      "epoch": 88.75,
      "learning_rate": 1.4062500000000001e-05,
      "loss": 0.0435,
      "step": 1420
    },
    {
      "epoch": 89.06,
      "learning_rate": 1.3671875e-05,
      "loss": 0.043,
      "step": 1425
    },
    {
      "epoch": 89.38,
      "learning_rate": 1.3281250000000001e-05,
      "loss": 0.0422,
      "step": 1430
    },
    {
      "epoch": 89.69,
      "learning_rate": 1.2890625e-05,
      "loss": 0.0438,
      "step": 1435
    },
    {
      "epoch": 90.0,
      "learning_rate": 1.25e-05,
      "loss": 0.0451,
      "step": 1440
    },
    {
      "epoch": 90.31,
      "learning_rate": 1.2109375000000001e-05,
      "loss": 0.0435,
      "step": 1445
    },
    {
      "epoch": 90.62,
      "learning_rate": 1.171875e-05,
      "loss": 0.0423,
      "step": 1450
    },
    {
      "epoch": 90.94,
      "learning_rate": 1.1328125000000001e-05,
      "loss": 0.0449,
      "step": 1455
    },
    {
      "epoch": 91.25,
      "learning_rate": 1.09375e-05,
      "loss": 0.0432,
      "step": 1460
    },
    {
      "epoch": 91.56,
      "learning_rate": 1.0546875e-05,
      "loss": 0.0427,
      "step": 1465
    },
    {
      "epoch": 91.88,
      "learning_rate": 1.0156250000000001e-05,
      "loss": 0.0426,
      "step": 1470
    },
    {
      "epoch": 92.19,
      "learning_rate": 9.765625e-06,
      "loss": 0.045,
      "step": 1475
    },
    {
      "epoch": 92.5,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.0447,
      "step": 1480
    },
    {
      "epoch": 92.81,
      "learning_rate": 8.984375e-06,
      "loss": 0.0429,
      "step": 1485
    },
    {
      "epoch": 93.12,
      "learning_rate": 8.59375e-06,
      "loss": 0.0405,
      "step": 1490
    },
    {
      "epoch": 93.44,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.0441,
      "step": 1495
    },
    {
      "epoch": 93.75,
      "learning_rate": 7.8125e-06,
      "loss": 0.0418,
      "step": 1500
    },
    {
      "epoch": 94.06,
      "learning_rate": 7.421875e-06,
      "loss": 0.045,
      "step": 1505
    },
    {
      "epoch": 94.38,
      "learning_rate": 7.031250000000001e-06,
      "loss": 0.0433,
      "step": 1510
    },
    {
      "epoch": 94.69,
      "learning_rate": 6.6406250000000005e-06,
      "loss": 0.0465,
      "step": 1515
    },
    {
      "epoch": 95.0,
      "learning_rate": 6.25e-06,
      "loss": 0.0482,
      "step": 1520
    },
    {
      "epoch": 95.31,
      "learning_rate": 5.859375e-06,
      "loss": 0.0449,
      "step": 1525
    },
    {
      "epoch": 95.62,
      "learning_rate": 5.46875e-06,
      "loss": 0.0447,
      "step": 1530
    },
    {
      "epoch": 95.94,
      "learning_rate": 5.078125000000001e-06,
      "loss": 0.0449,
      "step": 1535
    },
    {
      "epoch": 96.25,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.0452,
      "step": 1540
    },
    {
      "epoch": 96.56,
      "learning_rate": 4.296875e-06,
      "loss": 0.0436,
      "step": 1545
    },
    {
      "epoch": 96.88,
      "learning_rate": 3.90625e-06,
      "loss": 0.0459,
      "step": 1550
    },
    {
      "epoch": 97.19,
      "learning_rate": 3.5156250000000003e-06,
      "loss": 0.0439,
      "step": 1555
    },
    {
      "epoch": 97.5,
      "learning_rate": 3.125e-06,
      "loss": 0.0445,
      "step": 1560
    },
    {
      "epoch": 97.81,
      "learning_rate": 2.734375e-06,
      "loss": 0.0436,
      "step": 1565
    },
    {
      "epoch": 98.12,
      "learning_rate": 2.3437500000000002e-06,
      "loss": 0.0422,
      "step": 1570
    },
    {
      "epoch": 98.44,
      "learning_rate": 1.953125e-06,
      "loss": 0.0429,
      "step": 1575
    },
    {
      "epoch": 98.75,
      "learning_rate": 1.5625e-06,
      "loss": 0.0487,
      "step": 1580
    },
    {
      "epoch": 99.06,
      "learning_rate": 1.1718750000000001e-06,
      "loss": 0.0487,
      "step": 1585
    },
    {
      "epoch": 99.38,
      "learning_rate": 7.8125e-07,
      "loss": 0.0447,
      "step": 1590
    },
    {
      "epoch": 99.69,
      "learning_rate": 3.90625e-07,
      "loss": 0.0424,
      "step": 1595
    },
    {
      "epoch": 100.0,
      "learning_rate": 0.0,
      "loss": 0.0438,
      "step": 1600
    }
  ],
  "max_steps": 1600,
  "num_train_epochs": 100,
  "total_flos": 122783520000000.0,
  "trial_name": null,
  "trial_params": null
}
