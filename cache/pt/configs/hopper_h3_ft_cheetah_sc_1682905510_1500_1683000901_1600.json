{
  "act_dim": 3,
  "action_tanh": true,
  "activation_function": "relu",
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "drop_out": 0.1,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "hidden_size": 128,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_ep_len": 1000,
  "model_type": "decision_transformer",
  "n_head": 1,
  "n_inner": null,
  "n_layer": 3,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "state_dim": 11,
  "train_data_mean": [
    1.348777055188317,
    -0.1120823015555736,
    -0.5506466502855958,
    -0.13184914476646017,
    -0.0037875644148157453,
    2.607431961903589,
    0.023220604542072934,
    -0.016269193563024,
    -0.06840437937109121,
    -0.05183126604062714,
    0.04272716425778954
  ],
  "train_data_std": [
    0.159832954660356,
    0.04463086201214418,
    0.14312506697894511,
    0.17633949402438776,
    0.5913361383912005,
    0.5902023248437932,
    1.540777984224785,
    0.8155324590972153,
    2.017948630495211,
    2.411976914932518,
    5.846643384186645
  ],
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 1
}
